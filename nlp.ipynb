{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Day 1"
      ],
      "metadata": {
        "id": "cQwT9EgYsB-B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMTLxuRhc2dc"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "doc = nlp('Dr. Strange loves pav bhaji of Mumbai. Hulk loves chaat of Delhi')\n",
        "\n",
        "for sentence in doc.sents:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGjUBO0TdBeS",
        "outputId": "616701a7-e09f-420b-8e57-a21be69bd3a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr. Strange loves pav bhaji of Mumbai.\n",
            "Hulk loves chaat of Delhi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in doc.sents:\n",
        "  for words in sentence:\n",
        "    print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ng17U0sdrpm",
        "outputId": "d3fac992-db2e-4579-ffcb-5462427472b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr.\n",
            "Strange\n",
            "loves\n",
            "pav\n",
            "bhaji\n",
            "of\n",
            "Mumbai\n",
            ".\n",
            "Hulk\n",
            "loves\n",
            "chaat\n",
            "of\n",
            "Delhi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "sent_tokenize('Dr. Strange loves pav bhaji of Mumbai. Hulk loves chaat of Delhi')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5ZWQ2fydzbP",
        "outputId": "43ab69a3-6c87-4809-f4af-53a3342a765c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dr.', 'Strange loves pav bhaji of Mumbai.', 'Hulk loves chaat of Delhi']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize('Dr. Strange loves pav bhaji of Mumbai. Hulk loves chaat of Delhi')"
      ],
      "metadata": {
        "id": "I7BBLLQme4hw",
        "outputId": "d174afe7-efdd-4cb4-fc85-2d048448448e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dr',\n",
              " '.',\n",
              " 'Strange',\n",
              " 'loves',\n",
              " 'pav',\n",
              " 'bhaji',\n",
              " 'of',\n",
              " 'Mumbai',\n",
              " '.',\n",
              " 'Hulk',\n",
              " 'loves',\n",
              " 'chaat',\n",
              " 'of',\n",
              " 'Delhi']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Day 2"
      ],
      "metadata": {
        "id": "bkvNe3OPCwPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.blank('en')\n",
        "doc = nlp(\"captain america ate 100$ of samosa. Then he said i can do this all today\")\n",
        "\n",
        "for token in doc:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-OafLo5CkFt",
        "outputId": "a4dc1e1c-0840-4741-f41f-f15bfe714bf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "captain\n",
            "america\n",
            "ate\n",
            "100\n",
            "$\n",
            "of\n",
            "samosa\n",
            ".\n",
            "Then\n",
            "he\n",
            "said\n",
            "i\n",
            "can\n",
            "do\n",
            "this\n",
            "all\n",
            "today\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU4YROKSDMti",
        "outputId": "8107ee21-b06a-4f4d-b00b-db20d92cf1c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oMaiWszDQuz",
        "outputId": "1377175d-190f-40d8-98ed-b9e35e8cece7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x784ccfbda980>),\n",
              " ('tagger', <spacy.pipeline.tagger.Tagger at 0x784ccfbdb820>),\n",
              " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x784cd02bd770>),\n",
              " ('attribute_ruler',\n",
              "  <spacy.pipeline.attributeruler.AttributeRuler at 0x784ccfb5c340>),\n",
              " ('lemmatizer',\n",
              "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x784cd0095d80>),\n",
              " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x784cd02bd930>)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"captain america ate 100$ of samosa. Then he said i can do this all today\")\n",
        "doc = nlp(\"Sanjay is having fun\")\n",
        "\n",
        "for token in doc:\n",
        "  print(token, \"|\", token.pos_, \" | \", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHCkg1mmEo9N",
        "outputId": "35a07213-da2d-4206-d7fe-d2a6d801be71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanjay | PROPN  |  Sanjay\n",
            "is | AUX  |  be\n",
            "having | VERB  |  have\n",
            "fun | NOUN  |  fun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Tesla Inc is going to acquire twitter for 45$ Dollars\")\n",
        "from spacy import displacy\n",
        "\n",
        "displacy.render(doc, style=\"ent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "YSq-Aos7Km8C",
        "outputId": "fcc2bcd5-f6c4-4d5e-df6d-bb6b9b4f056d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Tesla Inc\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\\n</mark>\\n is going to acquire twitter for \\n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    45$ Dollars\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\\n</mark>\\n</div>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in doc.ents:\n",
        "  print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCny8joJorPl",
        "outputId": "ea8741a8-cf89-4c12-b66c-ecb86df66e6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla Inc  |  ORG  |  Companies, agencies, institutions, etc.\n",
            "45$ Dollars  |  MONEY  |  Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Day 3\n"
      ],
      "metadata": {
        "id": "rLOJT9-Vr6iK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy"
      ],
      "metadata": {
        "id": "LD7RHXSBpRov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "QDy94mTnse2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['eating','eats','eat','ate','adjustable','rafting','ability','meeting']\n",
        "\n",
        "for word in words:\n",
        "  print(word, \" | \", stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BKVKZr9s8Q8",
        "outputId": "2e281c3f-1d37-4fcb-9aed-ea3863d0c6ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating  |  eat\n",
            "eats  |  eat\n",
            "eat  |  eat\n",
            "ate  |  ate\n",
            "adjustable  |  adjust\n",
            "rafting  |  raft\n",
            "ability  |  abil\n",
            "meeting  |  meet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(\"eating eats eat ate adjustable rafting ability meeting\")\n",
        "\n",
        "for token in doc:\n",
        "  print(token, \" | \", token.lemma_, \" | \", token.lemma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DsPsnPTtZcv",
        "outputId": "2ccf0a5c-3e41-4e72-c97e-7f836a126a07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating  |  eat  |  9837207709914848172\n",
            "eats  |  eat  |  9837207709914848172\n",
            "eat  |  eat  |  9837207709914848172\n",
            "ate  |  eat  |  9837207709914848172\n",
            "adjustable  |  adjustable  |  6033511944150694480\n",
            "rafting  |  raft  |  7154368781129989833\n",
            "ability  |  ability  |  11565809527369121409\n",
            "meeting  |  meeting  |  14798207169164081740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0oslNcIu4SI",
        "outputId": "0ad04b54-95da-4dc1-d344-37e0486fd3f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Bro, You wanna go? Brah, don'ts say no! I am exhausted\")\n",
        "for token in doc:\n",
        "  print(token.text, \" | \", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qandUjOAu-oP",
        "outputId": "d6211ebf-1022-4ac2-beb3-c53e55bf2117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bro  |  bro\n",
            ",  |  ,\n",
            "You  |  you\n",
            "wanna  |  wanna\n",
            "go  |  go\n",
            "?  |  ?\n",
            "Brah  |  Brah\n",
            ",  |  ,\n",
            "don'ts  |  don't\n",
            "say  |  say\n",
            "no  |  no\n",
            "!  |  !\n",
            "I  |  I\n",
            "am  |  be\n",
            "exhausted  |  exhaust\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ar = nlp.get_pipe('attribute_ruler')\n",
        "ar.add([[{\"TEXT\": \"Bro\"}],[{\"TEXT\": \"Brah\"}]], {\"LEMMA\": \"Brother\"})\n",
        "\n",
        "doc = nlp(\"Bro, You wanna go? Brah, don't say no! I am exhausted\")\n",
        "for token in doc:\n",
        "  print(token.text, \" | \", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gc3f3d08vpQO",
        "outputId": "33c7f58b-7d0d-48f5-9998-6d99ed4bd930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bro  |  Brother\n",
            ",  |  ,\n",
            "You  |  you\n",
            "wanna  |  wanna\n",
            "go  |  go\n",
            "?  |  ?\n",
            "Brah  |  Brother\n",
            ",  |  ,\n",
            "do  |  do\n",
            "n't  |  not\n",
            "say  |  say\n",
            "no  |  no\n",
            "!  |  !\n",
            "I  |  I\n",
            "am  |  be\n",
            "exhausted  |  exhaust\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token.text, \" | \", token.pos_, \" | \", token.tag_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YReRTGXayOM3",
        "outputId": "56889952-e488-41b6-b7aa-8f9a01c23ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bro  |  NOUN  |  NN\n",
            ",  |  PUNCT  |  ,\n",
            "You  |  PRON  |  PRP\n",
            "wanna  |  AUX  |  MD\n",
            "go  |  VERB  |  VB\n",
            "?  |  PUNCT  |  .\n",
            "Brah  |  PROPN  |  NNP\n",
            ",  |  PUNCT  |  ,\n",
            "do  |  AUX  |  VBP\n",
            "n't  |  PART  |  RB\n",
            "say  |  VERB  |  VB\n",
            "no  |  INTJ  |  UH\n",
            "!  |  PUNCT  |  .\n",
            "I  |  PRON  |  PRP\n",
            "am  |  AUX  |  VBP\n",
            "exhausted  |  VERB  |  VBN\n"
          ]
        }
      ]
    }
  ]
}